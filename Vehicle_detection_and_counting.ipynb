{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJg86lkwa83f"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yYjMRtia_XZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "#plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Display image and videos\n",
        "import IPython\n",
        "from IPython.display import Video, display\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix-3tDg_bGNZ"
      },
      "outputs": [],
      "source": [
        "path = 'https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCFajbhybm3q"
      },
      "outputs": [],
      "source": [
        "frac = 0.65\n",
        "display(Video(data=path, height=int(720*frac), width=int(1280*frac)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HnabFTSbqMT"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8x.pt')\n",
        "#geting names from classes\n",
        "dict_classes = model.model.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d1SRtoKb4b2"
      },
      "outputs": [],
      "source": [
        "def risize_frame(frame, scale_percent):\n",
        "    \"\"\"Function to resize an image in a percent scale\"\"\"\n",
        "    width = int(frame.shape[1] * scale_percent / 100)\n",
        "    height = int(frame.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "\n",
        "    # resize image\n",
        "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "    return resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOUQXhfccBOh"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "# Scaling percentage of original frame\n",
        "scale_percent = 50\n",
        "\n",
        "\n",
        "#-------------------------------------------------------\n",
        "# Reading video with cv2\n",
        "video = cv2.VideoCapture(path)\n",
        "\n",
        "# Objects to detect Yolo\n",
        "class_IDS = [2, 3, 5, 7]\n",
        "# Auxiliary variables\n",
        "centers_old = {}\n",
        "centers_new = {}\n",
        "obj_id = 0\n",
        "veiculos_contador_in = dict.fromkeys(class_IDS, 0)\n",
        "veiculos_contador_out = dict.fromkeys(class_IDS, 0)\n",
        "end = []\n",
        "frames_list = []\n",
        "cy_linha = int(1500 * scale_percent/100 )\n",
        "cx_sentido = int(2000 * scale_percent/100)\n",
        "offset = int(8 * scale_percent/100 )\n",
        "contador_in = 0\n",
        "contador_out = 0\n",
        "print(f'[INFO] - Verbose during Prediction: {verbose}')\n",
        "\n",
        "\n",
        "# Original informations of video\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "print('[INFO] - Original Dim: ', (width, height))\n",
        "\n",
        "# Scaling Video for better performance\n",
        "if scale_percent != 100:\n",
        "    print('[INFO] - Scaling change may cause errors in pixels lines ')\n",
        "    width = int(width * scale_percent / 100)\n",
        "    height = int(height * scale_percent / 100)\n",
        "    print('[INFO] - Dim Scaled: ', (width, height))\n",
        "video_name = 'result.mp4'\n",
        "output_path = \"rep_\" + video_name\n",
        "tmp_output_path = \"tmp_\" + output_path\n",
        "\n",
        "VIDEO_CODEC = \"MP4V\"\n",
        "\n",
        "output_video = cv2.VideoWriter(tmp_output_path,\n",
        "                               cv2.VideoWriter_fourcc(*VIDEO_CODEC),\n",
        "                               fps, (width, height))\n",
        "\n",
        "for i in tqdm(range(int(video.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "\n",
        "    # reading frame from video\n",
        "    _, frame = video.read()\n",
        "\n",
        "    #Applying resizing of read frame\n",
        "    frame  = risize_frame(frame, scale_percent)\n",
        "\n",
        "    if verbose:\n",
        "        print('Dimension Scaled(frame): ', (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "    # Getting predictions\n",
        "    y_hat = model.predict(frame, conf = 0.7, classes = class_IDS, device = 'cpu', verbose = False)\n",
        "\n",
        "    # Getting the bounding boxes, confidence and classes of the recognize objects in the current frame.\n",
        "    boxes   = y_hat[0].boxes.xyxy.cpu().numpy()\n",
        "    conf    = y_hat[0].boxes.conf.cpu().numpy()\n",
        "    classes = y_hat[0].boxes.cls.cpu().numpy()\n",
        "\n",
        "    # Storing the above information in a dataframe\n",
        "    positions_frame = pd.DataFrame(y_hat[0].cpu().numpy().boxes.boxes, columns = ['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])\n",
        "    labels = [dict_classes[i] for i in classes]\n",
        "\n",
        "    # Drawing transition line for in\\out vehicles counting\n",
        "    cv2.line(frame, (0, cy_linha), (int(4500 * scale_percent/100 ), cy_linha), (255,255,0),8)\n",
        "\n",
        "    for ix, row in enumerate(positions_frame.iterrows()):\n",
        "        # Getting the coordinates of each vehicle (row)\n",
        "        xmin, ymin, xmax, ymax, confidence, category,  = row[1].astype('int')\n",
        "\n",
        "        # Calculating the center of the bounding-box\n",
        "        center_x, center_y = int(((xmax+xmin))/2), int((ymax+ ymin)/2)\n",
        "\n",
        "        # drawing center and bounding-box of vehicle in the given frame\n",
        "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (255,0,0), 5) # box\n",
        "        cv2.circle(frame, (center_x,center_y), 5,(255,0,0),-1) # center of box\n",
        "\n",
        "        #Drawing above the bounding-box the name of class recognized.\n",
        "        cv2.putText(img=frame, text=labels[ix]+' - '+str(np.round(conf[ix],2)),\n",
        "                    org= (xmin,ymin-10), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(255, 0, 0),thickness=2)\n",
        "\n",
        "        # Checking if the center of recognized vehicle is in the area given by the transition line + offset and transition line - offset\n",
        "        if (center_y < (cy_linha + offset)) and (center_y > (cy_linha - offset)):\n",
        "            if  (center_x >= 0) and (center_x <=cx_sentido):\n",
        "                contador_in +=1\n",
        "                veiculos_contador_in[category] += 1\n",
        "            else:\n",
        "              contador_out += 1\n",
        "              veiculos_contador_out[category] += 1\n",
        "\n",
        "    #updating the counting type of vehicle\n",
        "    contador_in_plt = [f'{dict_classes[k]}: {i}' for k, i in veiculos_contador_in.items()]\n",
        "    contador_out_plt = [f'{dict_classes[k]}: {i}' for k, i in veiculos_contador_out.items()]\n",
        "\n",
        "    #drawing the number of vehicles in\\out\n",
        "    cv2.putText(img=frame, text='N. vehicles In',\n",
        "                org= (30,30), fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
        "                fontScale=1, color=(255, 255, 0),thickness=1)\n",
        "\n",
        "    cv2.putText(img=frame, text='N. vehicles Out',\n",
        "                org= (int(2800 * scale_percent/100 ),30),\n",
        "                fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(255, 255, 0),thickness=1)\n",
        "\n",
        "    #drawing the counting of type of vehicles in the corners of frame\n",
        "    xt = 40\n",
        "    for txt in range(len(contador_in_plt)):\n",
        "        xt +=30\n",
        "        cv2.putText(img=frame, text=contador_in_plt[txt],\n",
        "                    org= (30,xt), fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
        "                    fontScale=1, color=(255, 255, 0),thickness=1)\n",
        "        cv2.putText(img=frame, text=contador_out_plt[txt],\n",
        "                    org= (int(2800 * scale_percent/100 ),xt), fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
        "                    fontScale=1, color=(255, 255, 0),thickness=1)\n",
        "\n",
        "    #drawing the number of vehicles in\\out\n",
        "    cv2.putText(img=frame, text=f'In:{contador_in}',\n",
        "                org= (int(1820 * scale_percent/100 ),cy_linha+60),\n",
        "                fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(255, 255, 0),thickness=2)\n",
        "\n",
        "    cv2.putText(img=frame, text=f'Out:{contador_out}',\n",
        "                org= (int(1800 * scale_percent/100 ),cy_linha-40),\n",
        "                fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(255, 255, 0),thickness=2)\n",
        "\n",
        "    if verbose:\n",
        "        print(contador_in, contador_out)\n",
        "    #Saving frames in a list\n",
        "    frames_list.append(frame)\n",
        "    output_video.write(frame)\n",
        "\n",
        "#Releasing the video\n",
        "output_video.release()\n",
        "\n",
        "\n",
        "####  pos processing\n",
        "# Fixing video output codec to run in the notebook\\browser\n",
        "if os.path.exists(output_path):\n",
        "    os.remove(output_path)\n",
        "\n",
        "subprocess.run(\n",
        "    [\"ffmpeg\",  \"-i\", tmp_output_path,\"-crf\",\"18\",\"-preset\",\"veryfast\",\"-hide_banner\",\"-loglevel\",\"error\",\"-vcodec\",\"libx264\",output_path])\n",
        "os.remove(tmp_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GtThmWzadu8d"
      },
      "outputs": [],
      "source": [
        "for i in [28, 29, 32, 40, 42, 50, 58]:\n",
        "    plt.figure(figsize =( 14, 10))\n",
        "    plt.imshow(frames_list[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L95re9F2d9hS"
      },
      "outputs": [],
      "source": [
        "frac = 0.7\n",
        "Video(data='rep_result.mp4', embed=True, height=int(720 * frac), width=int(1280 * frac))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bH3i7Rl8-_su"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}